{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.utils import normalize\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resizing images, if needed\n",
    "SIZE_X = 128\n",
    "SIZE_Y = 128\n",
    "n_classes = 4 #Number of classes for segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in masks: {0, 1, 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-27 13:26:16.820539: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define paths and constants\n",
    "train_image_dir = \"/Users/arahjou/Downloads/dataset_UWM_GI_Tract_train_valid/train/images/*.png\"\n",
    "train_mask_dir = \"/Users/arahjou/Downloads/dataset_UWM_GI_Tract_train_valid/train/masks/*.png\"\n",
    "IMG_SIZE = (SIZE_X, SIZE_Y)\n",
    "BATCH_SIZE = 12\n",
    "n_classes = 3  # Set this to the number of classes you have in your masks\n",
    "\n",
    "# Function to load and preprocess images and masks\n",
    "def load_image_and_mask(image_path, mask_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_png(image, channels=1)\n",
    "    image = tf.image.resize(image, IMG_SIZE)\n",
    "\n",
    "    mask = tf.io.read_file(mask_path)\n",
    "    mask = tf.image.decode_png(mask, channels=1)\n",
    "    mask = tf.image.resize(mask, IMG_SIZE, method='nearest')\n",
    "    mask = tf.cast(mask, tf.int32)  # Ensure mask is integer type\n",
    "    mask = tf.squeeze(mask, axis=-1)  # Remove last dimension\n",
    "    mask = tf.one_hot(mask, depth=n_classes)  # One-hot encode the mask\n",
    "    return image, mask\n",
    "\n",
    "# Function to normalize images and expand dimensions\n",
    "def preprocess(image, mask):\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, mask  # No need to expand dimensions of image or mask anymore\n",
    "\n",
    "# Creating the dataset\n",
    "image_paths = tf.data.Dataset.list_files(train_image_dir, seed=42)\n",
    "mask_paths = tf.data.Dataset.list_files(train_mask_dir, seed=42)\n",
    "dataset = tf.data.Dataset.zip((image_paths, mask_paths))\n",
    "dataset = dataset.map(load_image_and_mask, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "dataset = dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "dataset = dataset.shuffle(buffer_size=1000).batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Splitting the dataset into train, validation, and test sets\n",
    "val_size = int(0.1 * dataset.cardinality().numpy())\n",
    "test_size = int(0.1 * dataset.cardinality().numpy())\n",
    "train_dataset = dataset.skip(val_size + test_size)\n",
    "val_dataset = dataset.skip(test_size).take(val_size)\n",
    "test_dataset = dataset.take(test_size)\n",
    "\n",
    "# Example of how to get unique values in the masks for possible inspection\n",
    "def get_unique_values(mask_dataset):\n",
    "    unique_values = set()\n",
    "    for images, masks in mask_dataset.unbatch().batch(1):\n",
    "        unique_values.update(tf.reshape(masks, [-1, n_classes]).numpy().argmax(axis=1))\n",
    "    return unique_values\n",
    "\n",
    "unique_values = get_unique_values(test_dataset)\n",
    "print(\"Unique values in masks:\", unique_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
    "\n",
    "def multi_unet_model(n_classes=4, IMG_HEIGHT=256, IMG_WIDTH=256, IMG_CHANNELS=1):\n",
    "    # Build the model\n",
    "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "    # Inputs are already normalized in the preprocessing step\n",
    "    s = inputs\n",
    "\n",
    "    # Contraction path\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
    "    c1 = Dropout(0.1)(c1)\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    # Additional contraction and expansion layers as defined in your code\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "    c2 = Dropout(0.1)(c2)\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "     \n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "    c3 = Dropout(0.2)(c3)\n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "     \n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "    c4 = Dropout(0.2)(c4)\n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "     \n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "    c5 = Dropout(0.3)(c5)\n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "    \n",
    "    #Expansive path \n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "    c6 = Dropout(0.2)(c6)\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "     \n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "    c7 = Dropout(0.2)(c7)\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    "     \n",
    "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "    c8 = Dropout(0.1)(c8)\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "\n",
    "    # Expansive path (shortened for brevity)\n",
    "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)  # Ensure the axis is correctly set for concatenation\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "    c9 = Dropout(0.1)(c9)\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "    \n",
    "    # Output layer with softmax for multi-class segmentation\n",
    "    outputs = Conv2D(n_classes, (1, 1), activation='softmax')(c9)\n",
    "    \n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-27 13:36:33.206284: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {1.0: 1.525023353738962, 0.0: 0.743896882044764}\n",
      "Epoch 1/2\n",
      "\u001b[1m 93/884\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:44\u001b[0m 208ms/step - Accuracy: 0.8710 - loss: 1.1192"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 51\u001b[0m\n\u001b[1;32m     47\u001b[0m class_weights \u001b[38;5;241m=\u001b[39m compute_class_weights(train_dataset)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClass weights:\u001b[39m\u001b[38;5;124m\"\u001b[39m, class_weights)\n\u001b[0;32m---> 51\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     52\u001b[0m     train_dataset, \n\u001b[1;32m     53\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     54\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mval_dataset,\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m#class_weight=class_weights,\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     57\u001b[0m )\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Save the trained model\u001b[39;00m\n\u001b[1;32m     60\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest.keras\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/.C_Conda/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/.C_Conda/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:326\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    324\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m    325\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m--> 326\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(\n\u001b[1;32m    327\u001b[0m     step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    328\u001b[0m )\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/.C_Conda/lib/python3.12/site-packages/keras/src/callbacks/callback_list.py:106\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    104\u001b[0m logs \u001b[38;5;241m=\u001b[39m logs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m--> 106\u001b[0m     callback\u001b[38;5;241m.\u001b[39mon_train_batch_end(batch, logs\u001b[38;5;241m=\u001b[39mlogs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/.C_Conda/lib/python3.12/site-packages/keras/src/callbacks/progbar_logger.py:58\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_progbar(batch, logs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/.C_Conda/lib/python3.12/site-packages/keras/src/callbacks/progbar_logger.py:95\u001b[0m, in \u001b[0;36mProgbarLogger._update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m=\u001b[39m batch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# One-indexed.\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/.C_Conda/lib/python3.12/site-packages/keras/src/utils/progbar.py:163\u001b[0m, in \u001b[0;36mProgbar.update\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    160\u001b[0m info \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[k], \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    162\u001b[0m     avg \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mconvert_to_numpy(\n\u001b[0;32m--> 163\u001b[0m         backend\u001b[38;5;241m.\u001b[39mnumpy\u001b[38;5;241m.\u001b[39mmean(\n\u001b[1;32m    164\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[k][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[k][\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    165\u001b[0m         )\n\u001b[1;32m    166\u001b[0m     )\n\u001b[1;32m    167\u001b[0m     avg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(avg)\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(avg) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1e-3\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/.C_Conda/lib/python3.12/site-packages/keras/src/backend/tensorflow/numpy.py:489\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(x, axis, keepdims)\u001b[0m\n\u001b[1;32m    483\u001b[0m         gather_indices \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(rank) \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m axis]\n\u001b[1;32m    484\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mIndexedSlices(\n\u001b[1;32m    485\u001b[0m             tf\u001b[38;5;241m.\u001b[39mreduce_mean(x\u001b[38;5;241m.\u001b[39mvalues, axis\u001b[38;5;241m=\u001b[39maxis),\n\u001b[1;32m    486\u001b[0m             x\u001b[38;5;241m.\u001b[39mindices,\n\u001b[1;32m    487\u001b[0m             tf\u001b[38;5;241m.\u001b[39mgather(x\u001b[38;5;241m.\u001b[39mdense_shape, gather_indices, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m    488\u001b[0m         )\n\u001b[0;32m--> 489\u001b[0m x \u001b[38;5;241m=\u001b[39m convert_to_tensor(x)\n\u001b[1;32m    490\u001b[0m ori_dtype \u001b[38;5;241m=\u001b[39m standardize_dtype(x\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    491\u001b[0m compute_dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mresult_type(x\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/.C_Conda/lib/python3.12/site-packages/keras/src/backend/tensorflow/core.py:108\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(x, dtype, sparse)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m standardize_dtype(dtype)\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mis_tensor(x):\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbool\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;66;03m# TensorFlow boolean conversion is stricter than other backends.\u001b[39;00m\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;66;03m# It does not allow ints. We convert without dtype and cast instead.\u001b[39;00m\n\u001b[1;32m    112\u001b[0m         x \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/.C_Conda/lib/python3.12/site-packages/tensorflow/python/framework/tensor_util.py:1156\u001b[0m, in \u001b[0;36mis_tf_type\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_tf_type\u001b[39m(x):  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Checks whether `x` is a TF-native type that can be passed to many TF ops.\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \n\u001b[1;32m   1132\u001b[0m \u001b[38;5;124;03m  Use `is_tensor` to differentiate types that can ingested by TensorFlow ops\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[38;5;124;03m    `True` if `x` is a TensorFlow-native type.\u001b[39;00m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1156\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, tf_type_classes)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/.C_Conda/lib/python3.12/typing.py:1871\u001b[0m, in \u001b[0;36m_ProtocolMeta.__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__protocol_attrs__:\n\u001b[1;32m   1870\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1871\u001b[0m         val \u001b[38;5;241m=\u001b[39m getattr_static(instance, attr)\n\u001b[1;32m   1872\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m   1873\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/.C_Conda/lib/python3.12/inspect.py:1836\u001b[0m, in \u001b[0;36mgetattr_static\u001b[0;34m(obj, attr, default)\u001b[0m\n\u001b[1;32m   1834\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _static_getmro(objtype):\n\u001b[1;32m   1835\u001b[0m     klass \u001b[38;5;241m=\u001b[39m objtype\n\u001b[0;32m-> 1836\u001b[0m     dict_attr \u001b[38;5;241m=\u001b[39m _shadowed_dict(klass)\n\u001b[1;32m   1837\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (dict_attr \u001b[38;5;129;01mis\u001b[39;00m _sentinel \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1838\u001b[0m         \u001b[38;5;28mtype\u001b[39m(dict_attr) \u001b[38;5;129;01mis\u001b[39;00m types\u001b[38;5;241m.\u001b[39mMemberDescriptorType):\n\u001b[1;32m   1839\u001b[0m         instance_result \u001b[38;5;241m=\u001b[39m _check_instance(obj, attr)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/.C_Conda/lib/python3.12/inspect.py:1818\u001b[0m, in \u001b[0;36m_shadowed_dict\u001b[0;34m(klass)\u001b[0m\n\u001b[1;32m   1817\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_shadowed_dict\u001b[39m(klass):\n\u001b[0;32m-> 1818\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _shadowed_dict_from_mro_tuple(_static_getmro(klass))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Function to compute class weights directly from a TensorFlow dataset\n",
    "def compute_class_weights(dataset):\n",
    "    labels = []\n",
    "    for _, masks in dataset.unbatch().batch(1):\n",
    "        labels.extend(tf.reshape(masks, [-1]).numpy())\n",
    "    labels = tf.constant(labels)\n",
    "    \n",
    "    unique, _, counts = tf.unique_with_counts(labels)\n",
    "    total_counts = tf.reduce_sum(counts)\n",
    "    weights = total_counts / (len(unique) * counts)\n",
    "    \n",
    "    # Simply convert the whole tensor to numpy outside of the dictionary comprehension\n",
    "    unique = unique.numpy()\n",
    "    weights = weights.numpy()\n",
    "    class_weights = {k: v for k, v in zip(unique, weights)}\n",
    "    return class_weights\n",
    "\n",
    "\n",
    "# Define the Dice coefficient and Dice loss for model metrics and loss\n",
    "def dice_coefficient(y_true, y_pred, smooth=1e-6):\n",
    "    y_true_f = tf.cast(tf.reshape(y_true, [-1]), tf.float32)\n",
    "    y_pred_f = tf.cast(tf.reshape(y_pred, [-1]), tf.float32)\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1 - dice_coefficient(y_true, y_pred)\n",
    "\n",
    "\n",
    "# Define your model architecture and return it\n",
    "def get_model():\n",
    "    # Placeholder model architecture, replace with actual model\n",
    "    return multi_unet_model(n_classes=n_classes, IMG_HEIGHT=IMG_HEIGHT, IMG_WIDTH=IMG_WIDTH, IMG_CHANNELS=IMG_CHANNELS)\n",
    "\n",
    "# Model compilation and fitting\n",
    "IMG_HEIGHT = 128  # Adjust according to your data\n",
    "IMG_WIDTH = 128   # Adjust according to your data\n",
    "IMG_CHANNELS = 1 # Adjust according to your data\n",
    "n_classes = 3     # Adjust according to your data\n",
    "\n",
    "model = get_model()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['Accuracy'])\n",
    "\n",
    "# Assuming train_dataset and val_dataset have been defined earlier as tf.data.Dataset\n",
    "class_weights = compute_class_weights(train_dataset)\n",
    "print(\"Class weights:\", class_weights)\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset, \n",
    "    epochs=2,\n",
    "    validation_data=val_dataset,\n",
    "    #class_weight=class_weights,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "model.save('test.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.metrics import MeanIoU\n",
    "\n",
    "# Prepare to collect predictions and actuals\n",
    "y_pred_list = []\n",
    "y_true_list = []\n",
    "\n",
    "# Iterate over the test dataset\n",
    "for x_batch, y_batch in test_dataset:\n",
    "    y_pred = model.predict(x_batch)\n",
    "    y_pred_argmax = np.argmax(y_pred, axis=3)\n",
    "    y_true_list.append(y_batch.numpy()[:, :, :, 0])\n",
    "    y_pred_list.append(y_pred_argmax)\n",
    "\n",
    "# Convert lists to single numpy arrays\n",
    "y_true = np.concatenate(y_true_list, axis=0)\n",
    "y_pred_argmax = np.concatenate(y_pred_list, axis=0)\n",
    "\n",
    "# Calculate Mean IoU using Keras\n",
    "n_classes = 4\n",
    "IOU_keras = MeanIoU(num_classes=n_classes)\n",
    "IOU_keras.update_state(y_true, y_pred_argmax)\n",
    "print(\"Mean IoU =\", IOU_keras.result().numpy())\n",
    "confusion_mtx = IOU_keras.total_cm.numpy()  # Accessing the confusion matrix\n",
    "print(confusion_mtx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract a single batch from the dataset\n",
    "for x_batch, y_batch in test_dataset.take(1):\n",
    "    test_img = x_batch[0]  # Take the first image from the batch\n",
    "    ground_truth = y_batch[0]  # Corresponding ground truth\n",
    "    test_img_input = tf.expand_dims(test_img[:, :, 0], axis=0)  # Ensure dimensions are correct\n",
    "\n",
    "    # Make a prediction\n",
    "    prediction = model.predict(test_img_input)\n",
    "    predicted_img = np.argmax(prediction, axis=3)[0, :, :]  # Convert predictions to label format\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.subplot(231)\n",
    "    plt.title('Testing Image')\n",
    "    plt.imshow(test_img[:, :, 0], cmap='gray')  # Display the first channel\n",
    "    plt.subplot(232)\n",
    "    plt.title('Testing Label')\n",
    "    plt.imshow(ground_truth[:, :, 0], cmap='jet')  # Display the first channel of ground truth\n",
    "    plt.subplot(233)\n",
    "    plt.title('Prediction on test image')\n",
    "    plt.imshow(predicted_img, cmap='jet')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class-wise IoU from confusion matrix\n",
    "class_iou = []\n",
    "for i in range(n_classes):\n",
    "    iou = confusion_mtx[i, i] / (np.sum(confusion_mtx[i, :]) + np.sum(confusion_mtx[:, i]) - confusion_mtx[i, i])\n",
    "    class_iou.append(iou)\n",
    "    print(f\"IoU for class {i+1} is: {iou}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def label_to_color_image(label):\n",
    "    \"\"\"Convert a 2D array label to a color image.\n",
    "    \n",
    "    Args:\n",
    "        label: A 2D array with integer type, storing the segmentation label.\n",
    "    \n",
    "    Returns:\n",
    "        result: A 2D array with three channels (RGB), where each element in the label\n",
    "                is mapped to a corresponding RGB color.\n",
    "    \"\"\"\n",
    "    # Define the colormap\n",
    "    color_map = np.array([\n",
    "        [0, 0, 0],        # Class 0 -> Black\n",
    "        [255, 0, 0],      # Class 1 -> Red\n",
    "        [0, 255, 0],      # Class 2 -> Green\n",
    "        [0, 0, 255]       # Class 3 -> Blue\n",
    "    ])\n",
    "\n",
    "    # Map the label to the corresponding color\n",
    "    img = np.take(color_map, label, axis=0)\n",
    "\n",
    "    return img\n",
    "\n",
    "# Example usage:\n",
    "# Assuming 'predicted_img' is a 2D array with class labels as integers (output from argmax)\n",
    "# predicted_img_color = label_to_color_image(predicted_img)\n",
    "# plt.imshow(predicted_img_color)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x_batch, y_batch in test_dataset.take(1):\n",
    "    test_img = x_batch[0]  # First image in the batch\n",
    "    ground_truth = y_batch[0]  # Corresponding ground truth\n",
    "    test_img_input = tf.expand_dims(test_img[:, :, 0], axis=0)  # Prepare input\n",
    "\n",
    "    prediction = model.predict(test_img_input)\n",
    "    predicted_img = np.argmax(prediction, axis=3)[0, :, :]  # Convert predictions to label format\n",
    "    predicted_img_color = label_to_color_image(predicted_img)  # Convert to color\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.subplot(231)\n",
    "    plt.title('Testing Image')\n",
    "    plt.imshow(test_img[:, :, 0], cmap='gray')\n",
    "    plt.subplot(232)\n",
    "    plt.title('Testing Label')\n",
    "    plt.imshow(label_to_color_image(ground_truth[:, :, 0]))  # Display ground truth in color\n",
    "    plt.subplot(233)\n",
    "    plt.title('Prediction on test image')\n",
    "    plt.imshow(predicted_img_color)\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".C_Conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
