{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Conv2D,MaxPool2D,Flatten,Dropout,BatchNormalization,Activation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import load_img,img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'class_II', 'class_III', 'class_I']\n",
      "['class_I', 'class_II', 'class_III']\n",
      "Copying from: /Users/arahjou/Downloads/U_NET_GI_Segmentation/data/class_I to: /Users/arahjou/Downloads/U_NET_GI_Segmentation/data/dataset_model/train/class_I, /Users/arahjou/Downloads/U_NET_GI_Segmentation/data/dataset_model/validation/class_I, and /Users/arahjou/Downloads/U_NET_GI_Segmentation/data/dataset_model/test/class_I\n",
      "14286\n",
      "Copying from: /Users/arahjou/Downloads/U_NET_GI_Segmentation/data/class_II to: /Users/arahjou/Downloads/U_NET_GI_Segmentation/data/dataset_model/train/class_II, /Users/arahjou/Downloads/U_NET_GI_Segmentation/data/dataset_model/validation/class_II, and /Users/arahjou/Downloads/U_NET_GI_Segmentation/data/dataset_model/test/class_II\n",
      "16545\n",
      "Copying from: /Users/arahjou/Downloads/U_NET_GI_Segmentation/data/class_III to: /Users/arahjou/Downloads/U_NET_GI_Segmentation/data/dataset_model/train/class_III, /Users/arahjou/Downloads/U_NET_GI_Segmentation/data/dataset_model/validation/class_III, and /Users/arahjou/Downloads/U_NET_GI_Segmentation/data/dataset_model/test/class_III\n",
      "7663\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Updated split sizes\n",
    "train_split = 0.8\n",
    "valid_split = 0.1  # 10% of the remaining 20% after training split\n",
    "test_split = 0.1   # The rest to test\n",
    "\n",
    "categories = []\n",
    "\n",
    "source_folder = '/Users/arahjou/Downloads/U_NET_GI_Segmentation/data'\n",
    "folders = os.listdir(source_folder)\n",
    "print(folders)\n",
    "\n",
    "for subfolder in folders:\n",
    "    if os.path.isdir(os.path.join(source_folder, subfolder)):\n",
    "        categories.append(subfolder)\n",
    "\n",
    "categories.sort()\n",
    "print(categories)\n",
    "\n",
    "target_folder = \"/Users/arahjou/Downloads/U_NET_GI_Segmentation/data/dataset_model\"\n",
    "if not os.path.exists(target_folder):\n",
    "    os.mkdir(target_folder)\n",
    "\n",
    "trainPath = os.path.join(target_folder, \"train\")\n",
    "validatePath = os.path.join(target_folder, \"validation\")\n",
    "testPath = os.path.join(target_folder, \"test\")\n",
    "\n",
    "if not os.path.exists(trainPath):\n",
    "    os.mkdir(trainPath)\n",
    "if not os.path.exists(validatePath):\n",
    "    os.mkdir(validatePath)\n",
    "if not os.path.exists(testPath):\n",
    "    os.mkdir(testPath)\n",
    "\n",
    "def split_data(SOURCE, TRAINING, VALIDATION, TESTING, TRAIN_SPLIT, VALID_SPLIT):\n",
    "    files = []\n",
    "    for filename in os.listdir(SOURCE):\n",
    "        file = os.path.join(SOURCE, filename)\n",
    "        if os.path.getsize(file) > 0:\n",
    "            files.append(filename)\n",
    "        else:\n",
    "            print(f\"{filename} is 0 length, ignoring it ...\")\n",
    "    print(len(files))\n",
    "\n",
    "    trainingLength = int(len(files) * TRAIN_SPLIT)\n",
    "    validationLength = int(len(files) * VALID_SPLIT)\n",
    "\n",
    "    shuffleSet = random.sample(files, len(files))\n",
    "    trainingSet = shuffleSet[:trainingLength]\n",
    "    validationSet = shuffleSet[trainingLength:trainingLength + validationLength]\n",
    "    testSet = shuffleSet[trainingLength + validationLength:]\n",
    "\n",
    "    for filename in trainingSet:\n",
    "        thisFile = os.path.join(SOURCE, filename)\n",
    "        destination = os.path.join(TRAINING, filename)\n",
    "        shutil.copyfile(thisFile, destination)\n",
    "\n",
    "    for filename in validationSet:\n",
    "        thisFile = os.path.join(SOURCE, filename)\n",
    "        destination = os.path.join(VALIDATION, filename)\n",
    "        shutil.copyfile(thisFile, destination)\n",
    "\n",
    "    for filename in testSet:\n",
    "        thisFile = os.path.join(SOURCE, filename)\n",
    "        destination = os.path.join(TESTING, filename)\n",
    "        shutil.copyfile(thisFile, destination)\n",
    "\n",
    "for category in categories:\n",
    "    trainDestPath = os.path.join(trainPath, category)\n",
    "    validateDestPath = os.path.join(validatePath, category)\n",
    "    testDestPath = os.path.join(testPath, category)\n",
    "\n",
    "    if not os.path.exists(trainDestPath):\n",
    "        os.mkdir(trainDestPath)\n",
    "    if not os.path.exists(validateDestPath):\n",
    "        os.mkdir(validateDestPath)\n",
    "    if not os.path.exists(testDestPath):\n",
    "        os.mkdir(testDestPath)\n",
    "\n",
    "    sourcePath = os.path.join(source_folder, category)\n",
    "    print(f\"Copying from: {sourcePath} to: {trainDestPath}, {validateDestPath}, and {testDestPath}\")\n",
    "    split_data(sourcePath, trainDestPath, validateDestPath, testDestPath, train_split, valid_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_directory='/Users/arahjou/Downloads/U_NET_GI_Segmentation/data/dataset_model/train'\n",
    "val_directory='/Users/arahjou/Downloads/U_NET_GI_Segmentation/data/dataset_model/validation'\n",
    "test_directory='/Users/arahjou/Downloads/U_NET_GI_Segmentation/data/dataset_model/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1/255)\n",
    "val_datagen=ImageDataGenerator(rescale=1/255)\n",
    "test_datagen=ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30794 images belonging to 3 classes.\n",
      "Found 3848 images belonging to 3 classes.\n",
      "Found 3852 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator=train_datagen.flow_from_directory(train_directory,\n",
    "                                                 target_size=(224,224),\n",
    "                                                 color_mode='rgb',\n",
    "                                                 class_mode='sparse',batch_size=256)\n",
    "\n",
    "val_generator=val_datagen.flow_from_directory(val_directory,\n",
    "                                                 target_size=(224,224),\n",
    "                                                 color_mode='rgb',\n",
    "                                                 class_mode='sparse',batch_size=256)\n",
    "\n",
    "test_gemerator=test_datagen.flow_from_directory(test_directory,\n",
    "                                                 target_size=(224,224),\n",
    "                                                 color_mode='rgb',\n",
    "                                                 class_mode='sparse',batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes of body sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_I': 0, 'class_II': 1, 'class_III': 2}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning Using RESNET_101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 22:18:34.121486: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Pro\n",
      "2024-05-08 22:18:34.121508: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 18.00 GB\n",
      "2024-05-08 22:18:34.121516: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 6.00 GB\n",
      "2024-05-08 22:18:34.121534: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-05-08 22:18:34.121548: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m171317808/171317808\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import ResNet101V2\n",
    "convlayer=ResNet101V2(input_shape=(224,224,3),weights='imagenet',include_top=False)\n",
    "for layer in convlayer.layers:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ resnet101v2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ ?                      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">42,626,560</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ resnet101v2 (\u001b[38;5;33mFunctional\u001b[0m)        │ ?                      │    \u001b[38;5;34m42,626,560\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,626,560</span> (162.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m42,626,560\u001b[0m (162.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,626,560</span> (162.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m42,626,560\u001b[0m (162.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(convlayer)\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(2048,kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1024,kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(225,activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=tf.keras.optimizers.Adam(learning_rate= 0.001)\n",
    "model.compile(loss='sparse_categorical_crossentropy',metrics=['accuracy'],optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(train_generator,validation_data=val_generator,\n",
    "         epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30794 images belonging to 3 classes.\n",
      "Found 3848 images belonging to 3 classes.\n",
      "Found 3852 images belonging to 3 classes.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "2024-05-08 22:50:43.285551: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: INVALID_ARGUMENT: Incompatible shapes: [1,96] vs. [1,32]\n",
      "\t [[{{function_node __inference_one_step_on_data_66420}}{{node LogicalAnd_1}}]]\n",
      "2024-05-08 22:50:43.285570: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous send item cancelled. Key hash: 777814623529602584\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node LogicalAnd_1 defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 701, in start\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"/var/folders/j5/c5vt47v9695609y1ssl7zjdr0000gn/T/ipykernel_3867/3428510732.py\", line 89, in <module>\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 314, in fit\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 117, in one_step_on_iterator\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 104, in one_step_on_data\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 73, in train_step\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/keras/src/trainers/trainer.py\", line 412, in compute_metrics\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/keras/src/trainers/compile_utils.py\", line 330, in update_state\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/keras/src/trainers/compile_utils.py\", line 17, in update_state\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/keras/src/metrics/confusion_metrics.py\", line 378, in update_state\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/keras/src/metrics/metrics_utils.py\", line 592, in update_confusion_matrix_variables\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/keras/src/metrics/metrics_utils.py\", line 565, in weighted_assign_add\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/keras/src/ops/numpy.py\", line 3242, in logical_and\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/keras/src/backend/tensorflow/numpy.py\", line 1409, in logical_and\n\nIncompatible shapes: [1,96] vs. [1,32]\n\t [[{{node LogicalAnd_1}}]] [Op:__inference_one_step_on_iterator_67623]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 89\u001b[0m\n\u001b[1;32m     84\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     85\u001b[0m               optimizer\u001b[38;5;241m=\u001b[39mopt,\n\u001b[1;32m     86\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mPrecision(), tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mRecall()])\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Fit the model with class weights\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     90\u001b[0m     train_generator,\n\u001b[1;32m     91\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mval_generator,\n\u001b[1;32m     92\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m     93\u001b[0m     class_weight\u001b[38;5;241m=\u001b[39mclass_weights_dict\n\u001b[1;32m     94\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Com_Conda/.conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Documents/Com_Conda/.conda/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node LogicalAnd_1 defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 701, in start\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"/var/folders/j5/c5vt47v9695609y1ssl7zjdr0000gn/T/ipykernel_3867/3428510732.py\", line 89, in <module>\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 314, in fit\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 117, in one_step_on_iterator\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 104, in one_step_on_data\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 73, in train_step\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/keras/src/trainers/trainer.py\", line 412, in compute_metrics\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/keras/src/trainers/compile_utils.py\", line 330, in update_state\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/keras/src/trainers/compile_utils.py\", line 17, in update_state\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/keras/src/metrics/confusion_metrics.py\", line 378, in update_state\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/keras/src/metrics/metrics_utils.py\", line 592, in update_confusion_matrix_variables\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/keras/src/metrics/metrics_utils.py\", line 565, in weighted_assign_add\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/keras/src/ops/numpy.py\", line 3242, in logical_and\n\n  File \"/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/keras/src/backend/tensorflow/numpy.py\", line 1409, in logical_and\n\nIncompatible shapes: [1,96] vs. [1,32]\n\t [[{{node LogicalAnd_1}}]] [Op:__inference_one_step_on_iterator_67623]"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout, Flatten, BatchNormalization, Dense, Activation\n",
    "from tensorflow.keras.applications import ResNet101V2\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Directories\n",
    "train_directory = '/Users/arahjou/Downloads/U_NET_GI_Segmentation/data/dataset_model/train'\n",
    "val_directory = '/Users/arahjou/Downloads/U_NET_GI_Segmentation/data/dataset_model/validation'\n",
    "test_directory = '/Users/arahjou/Downloads/U_NET_GI_Segmentation/data/dataset_model/test'\n",
    "\n",
    "# Image Data Generators with augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1/255,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "val_datagen = ImageDataGenerator(rescale=1/255)\n",
    "test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# Data Generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_directory,\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='sparse',\n",
    "    batch_size=32\n",
    ")\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_directory,\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='sparse',\n",
    "    batch_size=32\n",
    ")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_directory,\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='sparse',\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_generator.classes),\n",
    "    y=train_generator.classes\n",
    ")\n",
    "class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "# Model architecture using ResNet101V2\n",
    "convlayer = ResNet101V2(input_shape=(224, 224, 3), weights='imagenet', include_top=False)\n",
    "for layer in convlayer.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = Sequential([\n",
    "    convlayer,\n",
    "    Dropout(0.5),\n",
    "    Flatten(),\n",
    "    BatchNormalization(),\n",
    "    Dense(2048, kernel_initializer='he_uniform'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1024, kernel_initializer='he_uniform'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(3, activation='softmax')  # Assuming 3 classes\n",
    "])\n",
    "\n",
    "#print(model.summary())\n",
    "\n",
    "# Compile the model\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "# Fit the model with class weights\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=5,\n",
    "    class_weight=class_weights_dict\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m 28/963\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:47\u001b[0m 628ms/step - accuracy: 0.3298 - loss: 1.9800"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      2\u001b[0m               optimizer\u001b[38;5;241m=\u001b[39mopt,\n\u001b[1;32m      3\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])  \u001b[38;5;66;03m# Temporarily remove precision and recall metrics\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m      6\u001b[0m     train_generator,\n\u001b[1;32m      7\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mval_generator,\n\u001b[1;32m      8\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m      9\u001b[0m     class_weight\u001b[38;5;241m=\u001b[39mclass_weights_dict\n\u001b[1;32m     10\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Com_Conda/.conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/Com_Conda/.conda/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m~/Documents/Com_Conda/.conda/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/Com_Conda/.conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Documents/Com_Conda/.conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[1;32m    880\u001b[0m )\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Com_Conda/.conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Com_Conda/.conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Documents/Com_Conda/.conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/Documents/Com_Conda/.conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Com_Conda/.conda/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1501\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1502\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1503\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1504\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1505\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1506\u001b[0m   )\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/Documents/Com_Conda/.conda/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])  # Temporarily remove precision and recall metrics\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=5,\n",
    "    class_weight=class_weights_dict\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with lower learning rate for last iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=tf.keras.optimizers.RMSprop(lr=0.0001)\n",
    "model.compile(loss='sparse_categorical_crossentropy',metrics=['accuracy'],optimizer=opt)\n",
    "history_1=model.fit(train_generator,validation_data=val_generator,\n",
    "         epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corrected code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30794 images belonging to 3 classes.\n",
      "Found 3848 images belonging to 3 classes.\n",
      "Found 3852 images belonging to 3 classes.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m187/963\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:17\u001b[0m 641ms/step - accuracy: 0.3430 - loss: 1.7329"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout, Flatten, BatchNormalization, Dense, Activation\n",
    "from tensorflow.keras.applications import ResNet101V2\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Directories\n",
    "train_directory = '/Users/arahjou/Downloads/U_NET_GI_Segmentation/data/dataset_model/train'\n",
    "val_directory = '/Users/arahjou/Downloads/U_NET_GI_Segmentation/data/dataset_model/validation'\n",
    "test_directory = '/Users/arahjou/Downloads/U_NET_GI_Segmentation/data/dataset_model/test'\n",
    "\n",
    "# Image Data Generators with augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1/255,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "val_datagen = ImageDataGenerator(rescale=1/255)\n",
    "test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# Data Generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_directory,\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='sparse',\n",
    "    batch_size=32\n",
    ")\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_directory,\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='sparse',\n",
    "    batch_size=32\n",
    ")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_directory,\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='sparse',\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_generator.classes),\n",
    "    y=train_generator.classes\n",
    ")\n",
    "class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "# Model architecture using ResNet101V2\n",
    "convlayer = ResNet101V2(input_shape=(224, 224, 3), weights='imagenet', include_top=False)\n",
    "for layer in convlayer.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = Sequential([\n",
    "    convlayer,\n",
    "    Dropout(0.5),\n",
    "    Flatten(),\n",
    "    BatchNormalization(),\n",
    "    Dense(2048, kernel_initializer='he_uniform'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1024, kernel_initializer='he_uniform'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(3, activation='softmax')  # Assuming 3 classes\n",
    "])\n",
    "\n",
    "# Compile the model with metrics initially removed to test\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit the model with class weights\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=5,\n",
    "    class_weight=class_weights_dict\n",
    ")\n",
    "\n",
    "# Optionally add and test precision and recall after initial tests\n",
    "precision = tf.keras.metrics.Precision()\n",
    "recall = tf.keras.metrics.Recall()\n",
    "\n",
    "for batch, (images, labels) in enumerate(val_generator):\n",
    "    preds = model.predict(images)\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    precision.update_state(labels, preds)\n",
    "    recall.update_state(labels, preds)\n",
    "\n",
    "    if batch >= len(val_generator) - 1:\n",
    "        break\n",
    "\n",
    "print(f'Precision: {precision.result().numpy()}, Recall: {recall.result().numpy()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'],c='red')\n",
    "plt.plot(history.history['val_accuracy'],c='green')\n",
    "plt.title('Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train','validation'],loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'],c='red')\n",
    "plt.plot(history.history['val_loss'],c='green')\n",
    "plt.title('Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train','validation'],loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_gemerator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "\n",
    "Function for prediciting section classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic=train_generator.class_indices\n",
    "icd={k:v for v,k in dic.items()}\n",
    "def output(location):\n",
    "    img=load_img(location,target_size=(224,224,3))\n",
    "    img=img_to_array(img)\n",
    "    img=img/255\n",
    "    img=np.expand_dims(img,[0])\n",
    "    answer=model.predict_classes(img)\n",
    "    probability=round(np.max(model.predict_proba(img)*100),2)\n",
    "    #print ('Bird Is',icd[answer[0]], 'With probability',probability)\n",
    "    print (probability, ' % chances are there that the Bird Is',icd[answer[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img='../input/anurag-mishra/belted.jpg'\n",
    "pic=load_img('../input/anurag-mishra/belted.jpg',target_size=(224,224,3))\n",
    "plt.imshow(pic)\n",
    "output(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img='../input/fdjn-vfvjkfd-v/hg.jpg'\n",
    "pic=load_img('../input/fdjn-vfvjkfd-v/hg.jpg',target_size=(224,224,3))\n",
    "plt.imshow(pic)\n",
    "output(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img='../input/fj-fdjvdk-vmdvdjl/bananan.jpg'\n",
    "pic=load_img('../input/fj-fdjvdk-vmdvdjl/bananan.jpg',target_size=(224,224,3))\n",
    "plt.imshow(pic)\n",
    "output(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": ".conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
