{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset_Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'class_II', 'class_III', 'class_I']\n",
      "['class_I', 'class_II', 'class_III']\n",
      "Copying from: /Users/arahjou/Downloads/U_NET_GI_Segmentation/data/class_I to: /Users/arahjou/Downloads/U_NET_GI_Segmentation/data/dataset_model/train/class_I and /Users/arahjou/Downloads/U_NET_GI_Segmentation/data/dataset_model/validation/class_I\n",
      "14286\n",
      "Copying from: /Users/arahjou/Downloads/U_NET_GI_Segmentation/data/class_II to: /Users/arahjou/Downloads/U_NET_GI_Segmentation/data/dataset_model/train/class_II and /Users/arahjou/Downloads/U_NET_GI_Segmentation/data/dataset_model/validation/class_II\n",
      "16545\n",
      "Copying from: /Users/arahjou/Downloads/U_NET_GI_Segmentation/data/class_III to: /Users/arahjou/Downloads/U_NET_GI_Segmentation/data/dataset_model/train/class_III and /Users/arahjou/Downloads/U_NET_GI_Segmentation/data/dataset_model/validation/class_III\n",
      "7663\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "splitsize = 0.85\n",
    "categories = []\n",
    "\n",
    "source_folder = '/Users/arahjou/Downloads/U_NET_GI_Segmentation/data'\n",
    "folders = os.listdir(source_folder)\n",
    "print(folders)\n",
    "\n",
    "for subfolder in folders:\n",
    "    if os.path.isdir(os.path.join(source_folder, subfolder)):\n",
    "        categories.append(subfolder)\n",
    "\n",
    "categories.sort()\n",
    "print(categories)\n",
    "\n",
    "target_folder = \"/Users/arahjou/Downloads/U_NET_GI_Segmentation/data/dataset_model\"\n",
    "if not os.path.exists(target_folder):\n",
    "    os.mkdir(target_folder)\n",
    "\n",
    "trainPath = os.path.join(target_folder, \"train\")\n",
    "validatePath = os.path.join(target_folder, \"validation\")\n",
    "\n",
    "if not os.path.exists(trainPath):\n",
    "    os.mkdir(trainPath)\n",
    "if not os.path.exists(validatePath):\n",
    "    os.mkdir(validatePath)\n",
    "\n",
    "def split_data(SOURCE, TRAINING, VALIDATION, SPLIT_SIZE):\n",
    "    files = []\n",
    "    for filename in os.listdir(SOURCE):\n",
    "        file = os.path.join(SOURCE, filename)\n",
    "        if os.path.getsize(file) > 0:\n",
    "            files.append(filename)\n",
    "        else:\n",
    "            print(f\"{filename} is 0 length, ignoring it ...\")\n",
    "    print(len(files))\n",
    "\n",
    "    trainingLength = int(len(files) * SPLIT_SIZE)\n",
    "    shuffleSet = random.sample(files, len(files))\n",
    "    trainingSet = shuffleSet[:trainingLength]\n",
    "    validSet = shuffleSet[trainingLength:]\n",
    "\n",
    "    for filename in trainingSet:\n",
    "        thisFile = os.path.join(SOURCE, filename)\n",
    "        destination = os.path.join(TRAINING, filename)\n",
    "        shutil.copyfile(thisFile, destination)\n",
    "\n",
    "    for filename in validSet:\n",
    "        thisFile = os.path.join(SOURCE, filename)\n",
    "        destination = os.path.join(VALIDATION, filename)\n",
    "        shutil.copyfile(thisFile, destination)\n",
    "\n",
    "for category in categories:\n",
    "    trainDestPath = os.path.join(trainPath, category)\n",
    "    validateDestPath = os.path.join(validatePath, category)\n",
    "\n",
    "    if not os.path.exists(trainDestPath):\n",
    "        os.mkdir(trainDestPath)\n",
    "    if not os.path.exists(validateDestPath):\n",
    "        os.mkdir(validateDestPath)\n",
    "\n",
    "    sourcePath = os.path.join(source_folder, category)\n",
    "    print(f\"Copying from: {sourcePath} to: {trainDestPath} and {validateDestPath}\")\n",
    "    split_data(sourcePath, trainDestPath, validateDestPath, splitsize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32719 images belonging to 3 classes.\n",
      "Found 5775 images belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/keras/src/applications/mobilenet_v3.py:512: UserWarning: `input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  return MobileNetV3(\n",
      "2024-05-08 20:38:05.411309: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Pro\n",
      "2024-05-08 20:38:05.411329: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 18.00 GB\n",
      "2024-05-08 20:38:05.411335: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 6.00 GB\n",
      "2024-05-08 20:38:05.411365: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-05-08 20:38:05.411375: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 20:38:07.703426: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "/Users/arahjou/Documents/Com_Conda/.conda/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m634s\u001b[0m 615ms/step - accuracy: 0.4138 - loss: 1.0712 - val_accuracy: 0.4329 - val_loss: 1.0576\n",
      "Epoch 2/5\n",
      "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 338ms/step - accuracy: 0.4313 - loss: 1.0549 - val_accuracy: 0.4289 - val_loss: 1.0535\n",
      "Epoch 3/5\n",
      "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 339ms/step - accuracy: 0.4366 - loss: 1.0508 - val_accuracy: 0.4376 - val_loss: 1.0524\n",
      "Epoch 4/5\n",
      "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 340ms/step - accuracy: 0.4375 - loss: 1.0482 - val_accuracy: 0.4395 - val_loss: 1.0536\n",
      "Epoch 5/5\n",
      "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 344ms/step - accuracy: 0.4413 - loss: 1.0457 - val_accuracy: 0.4324 - val_loss: 1.0517\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.applications import MobileNetV3Large\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "trainPath = \"/Users/arahjou/Downloads/U_NET_GI_Segmentation/data/dataset_model/train\"\n",
    "validPath = \"/Users/arahjou/Downloads/U_NET_GI_Segmentation/data/dataset_model/validation\"\n",
    "\n",
    "trainGenerator = ImageDataGenerator(\n",
    "    rotation_range=15, width_shift_range=0.1,\n",
    "    height_shift_range=0.1, brightness_range=(0.8, 1.2)\n",
    ").flow_from_directory(trainPath, target_size=(320, 320), batch_size=32)\n",
    "\n",
    "validGenerator = ImageDataGenerator(\n",
    "    rotation_range=15, width_shift_range=0.1,\n",
    "    height_shift_range=0.1, brightness_range=(0.8, 1.2)\n",
    ").flow_from_directory(validPath, target_size=(320, 320), batch_size=32)\n",
    "\n",
    "# Build the model\n",
    "baseModel = MobileNetV3Large(weights=\"imagenet\", include_top=False)\n",
    "\n",
    "x = baseModel.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "\n",
    "predictionLayer = Dense(3, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=baseModel.input, outputs=predictionLayer)\n",
    "\n",
    "# freezing the layers of the MobileNetV3 (already trained)\n",
    "\n",
    "for layer in model.layers[:-5]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile\n",
    "optimizer = Adam(learning_rate=0.0001)  # Correct argument name is `learning_rate`\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "model.fit(trainGenerator, validation_data=validGenerator, epochs=5)\n",
    "\n",
    "# Save the model\n",
    "modelSavedPath = \"/Users/arahjou/Downloads/U_NET_GI_Segmentation/model/MobileNetV3.keras\"\n",
    "model.save(modelSavedPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['class_I', 'class_II', 'class_III']\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/arahjou/Downloads/U_NET_GI_Segmentation/data/dataset_model/validation/class_III/slice_0015_360_310_1.50_1.50.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m     38\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/arahjou/Downloads/U_NET_GI_Segmentation/data/dataset_model/validation/class_III/slice_0015_360_310_1.50_1.50.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 39\u001b[0m resultText \u001b[38;5;241m=\u001b[39m classify_image(image_path)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(resultText)\n\u001b[1;32m     42\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(image_path)\n",
      "Cell \u001b[0;32mIn[3], line 19\u001b[0m, in \u001b[0;36mclassify_image\u001b[0;34m(imageFile)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclassify_image\u001b[39m(imageFile):\n\u001b[0;32m---> 19\u001b[0m     img \u001b[38;5;241m=\u001b[39m load_img(imageFile)  \u001b[38;5;66;03m# Use load_img for consistency with Keras\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mresize((\u001b[38;5;241m320\u001b[39m, \u001b[38;5;241m320\u001b[39m), Image\u001b[38;5;241m.\u001b[39mResampling\u001b[38;5;241m.\u001b[39mLANCZOS)  \u001b[38;5;66;03m# Use Resampling for resizing\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     x \u001b[38;5;241m=\u001b[39m img_to_array(img)\n",
      "File \u001b[0;32m~/Documents/Com_Conda/.conda/lib/python3.11/site-packages/keras/src/utils/image_utils.py:235\u001b[0m, in \u001b[0;36mload_img\u001b[0;34m(path, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, pathlib\u001b[38;5;241m.\u001b[39mPath):\n\u001b[1;32m    234\u001b[0m         path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(path\u001b[38;5;241m.\u001b[39mresolve())\n\u001b[0;32m--> 235\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    236\u001b[0m         img \u001b[38;5;241m=\u001b[39m pil_image\u001b[38;5;241m.\u001b[39mopen(io\u001b[38;5;241m.\u001b[39mBytesIO(f\u001b[38;5;241m.\u001b[39mread()))\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/arahjou/Downloads/U_NET_GI_Segmentation/data/dataset_model/validation/class_III/slice_0015_360_310_1.50_1.50.png'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# get the list of categories\n",
    "categories = os.listdir('/Users/arahjou/Downloads/U_NET_GI_Segmentation/data/dataset_model/train')\n",
    "categories.sort()\n",
    "print(categories)\n",
    "\n",
    "# load the saved model\n",
    "modelSavedPath = \"/Users/arahjou/Downloads/U_NET_GI_Segmentation/model/MobileNetV3.keras\"\n",
    "model = tf.keras.models.load_model(modelSavedPath)\n",
    "\n",
    "# predict the image\n",
    "def classify_image(imageFile):\n",
    "    img = load_img(imageFile)  # Use load_img for consistency with Keras\n",
    "    img = img.resize((320, 320), Image.Resampling.LANCZOS)  # Use Resampling for resizing\n",
    "\n",
    "    x = img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "\n",
    "    print(x.shape)\n",
    "    pred = model.predict(x)\n",
    "    print(pred)\n",
    "\n",
    "    # Get the highest prediction value\n",
    "    categoryValue = np.argmax(pred, axis=1)\n",
    "    categoryValue = categoryValue[0]\n",
    "\n",
    "    print(pred)\n",
    "\n",
    "    result = categories[categoryValue]\n",
    "    return result\n",
    "\n",
    "image_path = \"/Users/arahjou/Downloads/U_NET_GI_Segmentation/data/dataset_model/validation/class_III/slice_0015_360_310_1.50_1.50.png\"\n",
    "resultText = classify_image(image_path)\n",
    "print(resultText)\n",
    "\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.putText(image, resultText, (50,50), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 2)  # Use white color for text for visibility\n",
    "cv2.imshow('Image', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": ".conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
